## Lab: Scaling and Self Healing

### Background: Deployment Configurations and Replication Controllers

While *Services* provide routing and load balancing for *Pods*, which may go in and out of existence, *ReplicationControllers* (RC) are used to specify and then ensure the desired number of *Pods* (replicas) are in existence. For example, if you always want your application server to be scaled to 3 *Pods* (instances), a *ReplicationController* is needed. Without an RC, any *Pods* that are killed or somehow die/exit are not automatically restarted. *ReplicationControllers* are how OpenShift "self heals".

*Services* は、*Pods* のためのルーティングと負荷分散を提供しています, これは、存在すると出入りすることがあります, *ReplicationControllers* (RC) 指定して、必要な数を確保するために使用されている *Pods* (レプリカ) 存在している.たとえば、アプリケーションサーバーを常に 3 *Pods* (インスタンス) にスケーリングする場合は、*ReplicationController* が必要になります。rc がなければ、殺されるか、または何とか死ぬか、または出口が自動的に再始動されない *Pods*。*ReplicationControllers* はどのように OpenShift "自己治癒" です。

A *DeploymentConfiguration* (DC) defines how something in OpenShift should be deployed. From the https://{{DOCS_URL}}/latest/architecture/core_concepts/deployments.html#deployments-and-deployment-configurations[deployments documentation]:

A *DeploymentConfiguration* (DC) OpenShift で何かの配置方法を定義します。Https://{{DOCS_URL}}/latest/architecture/core_concepts/deployments.html#deployments-and-deployment-configurations[deployments ドキュメント]: から

[source]
----
Building on replication controllers, OpenShift adds expanded support for the software development and deployment lifecycle with the concept of deployments.  In the simplest case, a deployment just creates a new replication controller and lets it start up pods. However, OpenShift deployments also provide the ability to transition from an existing deployment of an image to a new one and also define hooks to be run before or after creating the replication controller.
----

In almost all cases, you will end up using the *Pod*, *Service*, *ReplicationController* and *DeploymentConfiguration* resources together. And, in almost all of those cases, OpenShift will create all of them for you.

ほぼすべてのケースでは結局使用する、*Pod* *Service* *ReplicationController* と *DeploymentConfiguration* 一緒にリソースです。そして、ほとんどすべてのそれらの場合、OpenShift はあなたのためそれらのすべてが作成されます。

There are some edge cases where you might want some *Pods* and an *RC* without a *DC* or a *Service*, and others, so feel free to ask us about them after the labs.

いくつかのエッジ ケースをいくつか場合があります *Pods* と *RC*、*DC* または *Service*、および他ので気軽にお問合せください実習後。

### Exercise: Exploring Deployment-related Objects

Now that we know the background of what a *ReplicatonController* and *DeploymentConfig* are, we can explore how they work and are related. Take a look at the *DeploymentConfig* (DC) that was created for you when you told OpenShift to stand up the `parksmap` image:

今、我々 は何の背景を知っている、*ReplicatonController* と *DeploymentConfig* は、仕事し、関連している方法について説明します。ぜひ、*DeploymentConfig* (DC) OpenShift `parksmap` イメージ立ち上がることを言ったときに作成されました。

[source]
----
$ oc get dc

NAME       REVISION   DESIRED   CURRENT   TRIGGERED BY
parksmap   1          1         1         config,image(parksmap:{{PARKSMAP_VERSION}})
----

To get more details, we can look into the *ReplicationController* (*RC*).

詳細を取得する我々 は調べることができます、*ReplicationController* (*RC*)。

Take a look at the *ReplicationController* (RC) that was created for you when you told OpenShift to stand up the `parksmap` image:

ぜひ、*ReplicationController* (RC) OpenShift `parksmap` イメージ立ち上がることを言ったときに作成されました。

[source]
----
$ oc get rc

NAME         DESIRED   CURRENT   READY     AGE
parksmap-1   1         1         0         4h
----

This lets us know that, right now, we expect one *Pod* to be deployed (`Desired`), and we have one *Pod* actually deployed (`Current`). By changing the desired number, we can tell OpenShift that we want more or less *Pods*.

これは、今知っている私たちをことができます、我々 は 1 つを期待 *Pod* する展開 (`希望`) そして用意ができました *Pod* (`現在`) を実際に配置します。希望の番号を変更すると、我々 言うことができる OpenShift もっとまたはより少なくしたい *Pods*。

OpenShift's *HorizontalPodAutoscaler* effectively monitors the CPU usage of a set of instances and then manipulates the RCs accordingly.

OpenShift の *HorizontalPodAutoscaler* 効果的に一連のインスタンスの CPU 使用率を監視し、それに応じて RCs を操作します。

You can learn more about the CPU-based https://{{DOCS_URL}}/latest/dev_guide/pod_autoscaling.html[Horizontal Pod Autoscaler here]

あなたは、CPU ベース https://{{DOCS_URL}}/latest/dev_guide/pod_autoscaling.html[Horizontal Pod Autoscaler]ついての詳細を学ぶことができます]
### Exercise: Scaling the Application

Let's scale our parksmap "application" up to 2 instances. We can do this with the `scale` command. You could also do this by clicking the "up" arrow next to the *Pod* in the OpenShift web console on the overview page. It's your choice.

私たちの parksmap の「アプリケーション」に 2 つのインスタンスを拡張しましょう。私たちは `scale` コマンドでこれを行うことができます。あなたが横に"up"の矢印をクリックしてこれを行うにも、*Pod* 概要のページに OpenShift web コンソールで。それはあなた次第です。

[source]
----
$ oc scale --replicas=2 dc/parksmap
----

To verify that we changed the number of replicas, issue the following command:

レプリカの数を変更したことを確認するには、次のコマンドを発行します。

[source]
----
$ oc get rc

NAME         DESIRED   CURRENT   READY     AGE
parksmap-1   2         2         0         4h
----

You can see that we now have 2 replicas. Let's verify the number of pods with the `oc get pods` command:

今 2 のレプリカがあることがわかります。`oc get pods` コマンドでポッドの数を確認してみましょう。

[source]
----
$ oc get pods

NAME               READY     STATUS    RESTARTS   AGE
parksmap-1-8g6lb   1/1       Running   0          1m
parksmap-1-hx0kv   1/1       Running   0          4h
----

And lastly, let's verify that the *Service* that we learned about in the previous lab accurately reflects two endpoints:

最後に、ことを確認しようと、*Service* 正確に前の実習で学んだこと 2 つのエンドポイントが反映されます。

[source]
----
$ oc describe svc parksmap
----

You will see something like the following output:

次の出力のようなものが表示されます。

[source]
----
Name:			parksmap
Namespace:		{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}
Labels:			app=parksmap
Selector:		deploymentconfig=parksmap
Type:			ClusterIP
IP:			172.30.169.213
Port:			8080-tcp	8080/TCP
Endpoints:		10.1.0.5:8080,10.1.1.5:8080
Session Affinity:	None
No events.
----

Another way to look at a *Service*'s endpoints is with the following:

別の方法を見て、*Service* のエンドポイントは次のように。

[source]
----
$ oc get endpoints parksmap
----

And you will see something like the following:

次のようが表示されます。

[source]
----
NAME       ENDPOINTS                                   AGE
parksmap   10.1.0.5:8080,10.1.1.5:8080                 4h
----

Your IP addresses will likely be different, as each pod receives a unique IP within the OpenShift environment. The endpoint list is a quick way to see how many pods are behind a service.

各ポッドは OpenShift 環境内で一意の IP を受信すると、IP アドレスは異なる、でしょう。エンドポイント リスト サービスの背後にあるどのように多くのポッドを確認する簡単な方法です。

You can also see that both *Pods* are running using the web console:

表示することができます両方 *Pods* を実行している web コンソールを使用して。

image::parksmap-scaled.png[Scaling]

Overall, that's how simple it is to scale an application (*Pods* in a *Service*). Application scaling can happen extremely quickly because OpenShift is just launching new instances of an existing image, especially if that image is already cached on the node.

全体的に、アプリケーションの拡張にそれがいかに簡単である (*Pods* で、*Service*)。アプリケーションのスケーリング起きるの非常に迅速には OpenShift が既存のイメージの新しいインスタンスを起動してちょうどそのイメージはノードに既にキャッシュされている場合は特に。

### Application "Self Healing"

Because OpenShift's *RCs* are constantly monitoring to see that the desired number of *Pods* actually is running, you might also expect that OpenShift will "fix" the situation if it is ever not right. You would be correct!

OpenShift の *RCs* 常に監視していることを確認する必要な数の *Pods* 実際に実行中に、OpenShift が「修正」の状況を期待するかもしれないも右はこれまで。あなたは正しいだろう!

Since we have two *Pods* running right now, let's see what happens if we "accidentally" kill one. Run the `oc get pods` command again, and choose a *Pod* name. Then, do the following:

我々 は 2 つを持っているので *Pods* 今、実行して何が起こるか見てみましょう我々 は「偶然」1 つを殺す場合。`oc get pods`コマンドを再度実行し、選択、*Pod* の名前。その後、次の操作を行います。

[source]
----
$ oc delete pod parksmap-1-hx0kv && oc get pods

pod "parksmap-1-h45hj" deleted
NAME               READY     STATUS              RESTARTS   AGE
parksmap-1-h45hj   1/1       Terminating         0          4m
parksmap-1-q4b4r   0/1       ContainerCreating   0          1s
parksmap-1-vdkd9   1/1       Running             0          32s
----

Did you notice anything? There is a container being terminated (the one we deleted), and there's a new container already being created.

何かに気づきましたか。(削除 1) 終了コンテナーが、既に作成された新しいコンテナーがあります。

Also, the names of the *Pods* are slightly changed.  That's because OpenShift almost immediately detected that the current state (1 *Pod*) didn't match the desired state (2 *Pods*), and it fixed it by scheduling another *Pod*.

またの名前、*Pods* が少し変更されました。 OpenShift はほとんどすぐに検出するためである現在の状態 (1 *Pod*) 目的の状態を一致していない (2 *Pods*)、それは別のスケジューリングによってそれを固定 *Pod*。

Additionally, OpenShift provides rudimentary capabilities around checking the liveness and/or readiness of application instances. If the basic checks are insufficient, OpenShift also allows you to run a command inside the container in order to perform the check. That command could be a complicated script that uses any installed language.

さらに、OpenShift は、活性および/またはアプリケーション インスタンスの準備をチェックする周辺の基本的な機能を提供します。基本のチェックでは不十分な場合 OpenShift は、チェックを実行するために、コンテナーの内部コマンドを実行することをもできます。このコマンドは、インストールされている言語を使用した複雑なスクリプト可能性があります。

Based on these health checks, if OpenShift decided that our `parksmap` application instance wasn't alive, it would kill the instance and then restart it, always ensuring that the desired number of replicas was in place.

これらの健康チェックに基づいて OpenShift が `parksmap` アプリケーション インスタンスが生きていないことを決定した場合、インスタンスを殺すや再起動する、常に確保目的のレプリカ数が適所にあったなります。

More information on probing applications is available in the https://{{DOCS_URL}}/latest/dev_guide/application_health.html[Application Health] section of the documentation.

徹底的なアプリケーションの詳細については https://{{DOCS_URL}}/latest/dev_guide/application_health.html[Application Health] で利用可能なドキュメントのセクション。
### Exercise: Scale Down

Before we continue, go ahead and scale your application down to a single instance. Feel free to do this using whatever method you like.

我々 は続行する前に、先に行くし、1 つのインスタンスにアプリケーションがスケール アップします。気軽にお好きな方法を使用してこれを行います。
