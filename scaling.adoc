## Lab: Scaling and Self Healing

### Background: Deployment Configurations and Replication Controllers

// [silver]#While *Services* provide routing and load balancing for *Pods*, which may go in and out of existence, *ReplicationControllers* (RC) are used to specify and then ensure the desired number of *Pods* (replicas) are in existence. For example, if you always want your application server to be scaled to 3 *Pods* (instances), a *ReplicationController* is needed. Without an RC, any *Pods* that are killed or somehow die/exit are not automatically restarted. *ReplicationControllers* are how OpenShift "self heals".#

*Services* は、スケールアップ・ダウンする *Pods* のためのルーティングと負荷分散を提供しています。 ReplicationControllers* (RC) 、必要な数の *Pod* が動作しているかをチェックします。例えば、常に 3 pod 動作している状態を保つするための役割を ReplicationController は果たします。もし、Replication Controllerがなければ、Pod が不正に終了してしまった場合などに再起動ができなくなります。ReplicationControllerは　OpenShift のセルフヒーリングの機能を提供します。

// [silver]#A *DeploymentConfiguration* (DC) defines how something in OpenShift should be deployed. From the https://{{DOCS_URL}}/latest/architecture/core_concepts/deployments.html#deployments-and-deployment-configurations[deployments documentation]:#

*DeploymentConfiguration* (DC)は OpenShift での Pod の配置方法を定義します。https://{{DOCS_URL}}/latest/architecture/core_concepts/deployments.html#deployments-and-deployment-configurations[deployments ドキュメント] の抜粋

[source]
----
Building on replication controllers, OpenShift adds expanded support for the software development and deployment lifecycle with the concept of deployments.  In the simplest case, a deployment just creates a new replication controller and lets it start up pods. However, OpenShift deployments also provide the ability to transition from an existing deployment of an image to a new one and also define hooks to be run before or after creating the replication controller.

OpenShiftは、ソフトウェア開発とデプロイのコンセプトとともにデプロイライフサイクル管理の機能を提供しています。もっともシンプルなケースでは、デプロイメントは Replication Controller を作成し、Podを起動します。しかしながら、OpenShiftのdeploymentsは、デプロイ済みのイメージから新しいイメージへの更新をする機能も提供し、また、そのトリガも定義います。
----

// [silver]#In almost all cases, you will end up using the *Pod*, *Service*, *ReplicationController* and *DeploymentConfiguration* resources together. And, in almost all of those cases, OpenShift will create all of them for you.#

ほぼすべてのケースで、*Pod*、*Service*、 *ReplicationController* と *DeploymentConfiguration* が利用されるリソースです。


image::scalling-dc-rc.png[DC RC]


### Exercise: Exploring Deployment-related Objects

// [silver]#Now that we know the background of what a *ReplicatonController* and *DeploymentConfig* are, we can explore how they work and are related. Take a look at the *DeploymentConfig* (DC) that was created for you when you told OpenShift to stand up the `parksmap` image:#

`parksmap` イメージが開始された時に、*DeploymentConfig* (DC) が作成されているので確認します。

[source]
----
$ oc get dc

NAME       REVISION   DESIRED   CURRENT   TRIGGERED BY
parksmap   1          1         1         config,image(parksmap:{{PARKSMAP_VERSION}})
----

// [silver]#To get more details, we can look into the *ReplicationController* (*RC*).#
// [silver]#Take a look at the *ReplicationController* (RC) that was created for you when you told OpenShift to stand up the `parksmap` image:#

*ReplicationController*  (RC) もできていますので、こちらも確認します。

[source]
----
$ oc get rc

NAME         DESIRED   CURRENT   READY     AGE
parksmap-1   1         1         0         4h
----

// [silver]#This lets us know that, right now, we expect one *Pod* to be deployed (`Desired`), and we have one *Pod* actually deployed (`Current`). By changing the desired number, we can tell OpenShift that we want more or less *Pods*.#

この出力結果は 1 *Pod* (`Desired`) が稼働してることを期待しており、1 *Pod* が配備 (`Current`) をを確認することができます。

// [silver]#OpenShift's *HorizontalPodAutoscaler* effectively monitors the CPU usage of a set of instances and then manipulates the RCs accordingly.#

OpenShift の *HorizontalPodAutoscaler* はCPU の使用率を監視し、それに応じてRCの操作をしてインスタンスの増減をします。

// [silver]#You can learn more about the CPU-based https://{{DOCS_URL}}/latest/dev_guide/pod_autoscaling.html[Horizontal Pod Autoscaler here]#

CPU ベースのオートスケールの詳細は https://{{DOCS_URL}}/latest/dev_guide/pod_autoscaling.html[Horizontal Pod Autoscaler] を参照してください。

### Exercise: Scaling the Application

// [silver]#Let's scale our parksmap "application" up to 2 instances. We can do this with the `scale` command. You could also do this by clicking the "up" arrow next to the *Pod* in the OpenShift web console on the overview page. It's your choice.#


`parksmap` アプリケーションのインスタンス数を2に拡張します。この操作には `oc scale` コマンドを利用します。GUIで実施する場合には、*Pod* の概要ページの Pod 数の丸の隣にある 上、下のボタンをクリックします。


[source]
----
$ oc scale --replicas=2 dc/parksmap
----

// [silver]#To verify that we changed the number of replicas, issue the following command:#

レプリカの数を変更したことを確認するには、次のコマンドを発行します。

[source]
----
$ oc get rc

NAME         DESIRED   CURRENT   READY     AGE
parksmap-1   2         2         0         4h
----

// [silver]#You can see that we now have 2 replicas. Let's verify the number of pods with the `oc get pods` command:#

今 2 のレプリカがあることがわかります。`oc get pods` コマンドでポッドの数を確認してみましょう。

[source]
----
$ oc get pods

NAME               READY     STATUS    RESTARTS   AGE
parksmap-1-8g6lb   1/1       Running   0          1m
parksmap-1-hx0kv   1/1       Running   0          4h
----

// [silver]#And lastly, let's verify that the *Service* that we learned about in the previous lab accurately reflects two endpoints:#

最後に、*Service* に 2 つのエンドポイントが反映されます。

[source]
----
$ oc describe svc parksmap
----

// [silver]#You will see something like the following output:#

次の出力のようなものが表示されます。

[source]
----
Name:			parksmap
Namespace:		{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}
Labels:			app=parksmap
Selector:		deploymentconfig=parksmap
Type:			ClusterIP
IP:			172.30.169.213
Port:			8080-tcp	8080/TCP
Endpoints:		10.1.0.5:8080,10.1.1.5:8080
Session Affinity:	None
No events.
----

// [silver]#Another way to look at a *Service*'s endpoints is with the following:#

*Service* のエンドポイントを確認することも可能です。

[source]
----
$ oc get endpoints parksmap
----

// [silver]#And you will see something like the following:#

次のようが表示されます。

[source]
----
NAME       ENDPOINTS                                   AGE
parksmap   10.1.0.5:8080,10.1.1.5:8080                 4h
----

// [silver]#Your IP addresses will likely be different, as each pod receives a unique IP within the OpenShift environment. The endpoint list is a quick way to see how many pods are behind a service.#

出力されるIPアドレスは、環境によって異なります。Endpoint の一覧は、Service のバックエンドにある Pod の数分が表示されます。

// [silver]#You can also see that both *Pods* are running using the web console:#

web コンソールを使用して。実行中の両方の *Pods* を表示することができます。

image::parksmap-scaled.png[Scaling]

// [silver]#Overall, that's how simple it is to scale an application (*Pods* in a *Service*). Application scaling can happen extremely quickly because OpenShift is just launching new instances of an existing image, especially if that image is already cached on the node.#

アプリケーション（ *Service* のバックエンドにある *Pod* ) のスケールは簡単で、OPenShift 上で Service のバックエンドにある Pod を増やすだけです。すでに、コンテナイメージがキャッシュされていれば即座に実行されます。

### Application "Self Healing"

// [silver]#Because OpenShift's *RCs* are constantly monitoring to see that the desired number of *Pods* actually is running, you might also expect that OpenShift will "fix" the situation if it is ever not right. You would be correct!#

OpenShift の *Replication Controller* (RC) は、常に必要な数のPodが稼働しているかを監視しています。

// [silver]#Since we have two *Pods* running right now, let's see what happens if we "accidentally" kill one. Run the `oc get pods` command again, and choose a *Pod* name. Then, do the following:#

`parksmap` アプリケーションの Pod が 2 つ稼働中なので、コマンドラインから1つ削除してみましょう。

[source]
----
$ oc delete pod parksmap-1-hx0kv && oc get pods

pod "parksmap-1-h45hj" deleted
NAME               READY     STATUS              RESTARTS   AGE
parksmap-1-h45hj   1/1       Terminating         0          4m
parksmap-1-q4b4r   0/1       ContainerCreating   0          1s
parksmap-1-vdkd9   1/1       Running             0          32s
----

// [silver]#Did you notice anything? There is a container being terminated (the one we deleted), and there's a new container already being created.#

Replication Controller が期待するPod数が2なのに対して、稼働中なPodが1に減ったことを検知して、すでに、新しいコンテナの作成が開始されています。

// [silver]#Also, the names of the *Pods* are slightly changed.  That's because OpenShift almost immediately detected that the current state (1 *Pod*) didn't match the desired state (2 *Pods*), and it fixed it by scheduling another *Pod*.#

Pod は起動されるたびに新しい名前が割り当てられます。

// [silver]#Additionally, OpenShift provides rudimentary capabilities around checking the liveness and/or readiness of application instances. If the basic checks are insufficient, OpenShift also allows you to run a command inside the container in order to perform the check. That command could be a complicated script that uses any installed language.#

さらに、OpenShift は、アプリケーションインスタンスの liveness / readiness をチェックするための初歩的な機能を提供します。基本チェックが不十分な場合、OpenShift では、チェックを実行するためにコンテナ内でコマンドを実行することもできます。このコマンドは、利用可能なプログラミング言語で複雑なスクリプトを定義することも可能です。

// [silver]#Based on these health checks, if OpenShift decided that our `parksmap` application instance wasn't alive, it would kill the instance and then restart it, always ensuring that the desired number of replicas was in place.#

これらのヘルスチェックに基づいて OpenShift が `parksmap` アプリケーション インスタンスが生きていないことを検出した場合、インスタンスのkillや再起動して、常に期待する数の正常な状態のPodが稼働しているように保ちます。

// [silver]#More information on probing applications is available in the https://{{DOCS_URL}}/latest/dev_guide/application_health.html[Application Health] section of the documentation.#

詳細については https://{{DOCS_URL}}/latest/dev_guide/application_health.html[Application Health] を参照してください。

### Exercise: Scale Down

// [silver]#Before we continue, go ahead and scale your application down to a single instance. Feel free to do this using whatever method you like.#

次のラボに進む前にPod数を1にスケールダウンします。
